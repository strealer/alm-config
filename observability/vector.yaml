# Vector configuration for Strealer ALM edge devices
# Optimized for Raspberry Pi 4 (Resource Constrained)

api:
  enabled: true
  address: "0.0.0.0:8686"

# ============================================================================
# SOURCES
# ============================================================================

sources:
  nginx_access:
    type: file
    include: ["/var/log/nginx/access*.log"]
    read_from: end
    max_line_bytes: 102400

  nginx_error:
    type: file
    include: ["/var/log/nginx/error*.log"]
    read_from: end
    max_line_bytes: 102400

  docker_containers:
    type: docker_logs
    docker_host: "unix:///var/run/docker.sock"
    include_containers: ["alm_arm64", "alm_telemetry", "alm_init"]
    exclude_containers: []
    partial_event_marker_field: "_partial"
    auto_partial_merge: true

  system_logs:
    type: journald
    include_units: ["docker", "systemd"]

  # Internal Vector metrics for self-monitoring
  vector_metrics:
    type: internal_metrics
    namespace: vector

  # Host system metrics (CPU, Memory, Disk, Network)
  host_metrics:
    type: host_metrics
    collectors:
      - cpu           # CPU usage per core and total
      - memory        # Memory usage (used, available, free, cached)
      - disk          # Disk I/O statistics
      - filesystem    # Filesystem usage per mount point
      - network       # Network I/O per interface
      - load          # System load averages (1m, 5m, 15m)
    scrape_interval_secs: 15
    namespace: host

  # Collect IP information (Local and Public)
  ip_info:
    type: "exec"
    command: ["/bin/sh", "-c", "echo \"{\\\"public_ip\\\": \\\"$(wget -qO- checkip.amazonaws.com)\\\", \\\"local_ip\\\": \\\"$(ip route get 1.1.1.1 | awk '{print $7}')\\\"}\""]
    mode: "scheduled"
    scheduled:
      exec_interval_secs: 3600  # Run every hour
    decoding:
      codec: "json"

# ============================================================================
# TRANSFORMS
# ============================================================================

transforms:
  # Optimize Nginx parsing for CPU efficiency
  parse_nginx_access:
    type: remap
    inputs: ["nginx_access"]
    drop_on_error: true
    reroute_dropped: true
    source: |
      message = string!(.message)
      .source_type = "nginx_access"
      
      # Parse nginx custom log format
      # Format: "FT | $time_iso8601 | $status | $request | $upstream_cache_status | $body_bytes_sent"
      parsed, err = parse_regex(message, r'^(?P<log_type>[A-Z]+) \| (?P<timestamp>[^ ]+) \| (?P<status>\d+) \| (?P<request>[^|]+) \| (?P<cache_status>[^|]+) \| (?P<bytes>\d+)$')
      
      if err == null {
        .log_type = parsed.log_type
        .timestamp = parse_timestamp!(parsed.timestamp, "%Y-%m-%dT%H:%M:%S%z")
        .status = to_int!(parsed.status)
        .request = parsed.request
        .cache_status = parsed.cache_status
        .bytes_sent = to_int!(parsed.bytes)
        
        # Extract request method and path
        request_parts = split!(parsed.request, " ", limit: 3)
        .method = request_parts[0]
        .path = request_parts[1]
        .http_version = request_parts[2]
        
        # Categorize by cache type
        if contains(string!(.path), "/media") {
          .cache_type = "media"
        } else if contains(string!(.path), "/player") {
          .cache_type = "player"
        } else if contains(string!(.path), "/renderer") {
          .cache_type = "renderer"
        } else {
          .cache_type = "other"
        }
      }
  # Sampling for high-volume logs (keep every 10th success)
  sample_nginx_access:
    type: sample
    inputs: ["parse_nginx_access"]
    rate: 10

  # Add device metadata (using Lua for consistency and file reading)
  add_metadata:
    type: lua
    inputs: ["sample_nginx_access", "nginx_error", "docker_containers", "system_logs", "ip_info"]
    version: "2"
    hooks:
      process: |
        function (event, emit)
          -- Lazy load hostname from file
          if not _G.device_hostname then
            local f = io.open("/etc/hostname", "r")
            if f then
              local content = f:read("*all")
              f:close()
              content = content:gsub("%s+", "")
              local parts = {}
              for part in string.gmatch(content, "[^-]+") do
                table.insert(parts, part)
              end
              if #parts >= 2 then
                _G.device_hostname = parts[2]
              else
                _G.device_hostname = content
              end
            else
              _G.device_hostname = "unknown"
            end
          end

          if _G.device_hostname then
            event.log.device_hostname = _G.device_hostname
          end
          event.log.device_role = "alm-edge"
          event.log.environment = "production"
          if not event.log.cache_status then
            event.log.cache_status = "N/A"
          end
          emit(event)
        end

  # Enrich host metrics with correct hostname from mounted file (using Lua since VRL can't read files)
  enrich_host_metrics:
    type: lua
    inputs: ["host_metrics"]
    version: "2"
    hooks:
      process: |
        function (event, emit)
          -- Lazy load hostname from file
          if not _G.device_hostname then
            local f = io.open("/etc/hostname", "r")
            if f then
              local content = f:read("*all")
              f:close()
              content = content:gsub("%s+", "")
              local parts = {}
              for part in string.gmatch(content, "[^-]+") do
                table.insert(parts, part)
              end
              if #parts >= 2 then
                _G.device_hostname = parts[2]
              else
                _G.device_hostname = content
              end
            else
              _G.device_hostname = "unknown"
            end
          end

          if _G.device_hostname then
            event.metric.tags.host = _G.device_hostname
          end
          emit(event)
        end

  # Generate metrics from logs (for Prometheus)
  log_metrics:
    type: log_to_metric
    inputs: ["add_metadata"]
    metrics:
      - type: counter
        field: status
        name: http_requests_total
        namespace: strealer
        tags:
          status: "{{ status }}"
          method: "{{ method }}"
          cache_status: "{{ cache_status }}"

# ============================================================================
# SINKS
# ============================================================================

sinks:
  loki:
    type: loki
    inputs: ["add_metadata"]
    endpoint: "${LOKI_ENDPOINT:-http://your-loki-server:3100}"
    encoding:
      codec: json
    healthcheck:
      enabled: true
    compression: snappy
    
    # Reduced label cardinality for Loki performance
    labels:
      device: "{{ device_hostname }}"
      role: "alm-edge"
      env: "production"
      log_source: "{{ source_type }}"
      cache_status: "{{ cache_status }}"
    
    # Disk buffering for edge resilience
    buffer:
      type: disk
      max_size: 283115520  # 270MB (increased from 256MB to satisfy min requirement)
      when_full: block
    
    # Optimized batching for edge
    batch:
      max_bytes: 262144  # 256KB
      timeout_secs: 15
      max_events: 1000
    
    # Request limits
    request:
      timeout_secs: 30
      rate_limit_num: 100
      rate_limit_duration_secs: 1
      retry_attempts: 5
    
    # Data durability
    acknowledgements:
      enabled: true

  # Metrics: Push to Prometheus (Remote Write)
  prometheus_remote_write:
    type: prometheus_remote_write
    inputs: ["log_metrics", "vector_metrics", "enrich_host_metrics"]  # Send generated metrics + internal + enriched host metrics
    endpoint: "${PROMETHEUS_ENDPOINT:-http://your-prometheus:9090}/api/v1/write"
    default_namespace: "strealer"
    healthcheck:
      enabled: true

  # Expose metrics locally for scraping (optional backup)
  prometheus_exporter:
    type: prometheus_exporter
    inputs: ["log_metrics", "vector_metrics", "enrich_host_metrics"]
    address: "0.0.0.0:9598"
    default_namespace: "strealer"
