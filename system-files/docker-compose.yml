# ============================================================================
# Strealer ALM Multi-Container Stack (Zeroâ€‘Touch Registration)
# ----------------------------------------------------------------------------
# - **Init phase** (`alm_init_*`): BASH-only bootstrap that registers the device,
#   pulls configuration from fapi-staging, writes shared volumes, then exits.
# - **Main phase** (`alm_*`): ALM Java application with nginx cache exposed on
#   port 80. Services wait on init completion via depends_on conditions.
# - **Telemetry phase** (`alm_telemetry`): Cron sidecar that runs the legacy
#   `cron_5m.sh` workflow every five minutes using the same volumes.
# - **Images**: Multi-arch images are pulled from
#   `europe-west1-docker.pkg.dev/...`. Puppet performs the `docker login`
#   before each pull on real devices. Override tags via `ALM_*_TAG` environment
#   pinning specific versions.
# - **Volumes**: `alm_config` and `alm_persist` are Docker named volumes so no
#   host bind mounts are required.
# - **Networking**: Init containers use `network_mode: host` strictly to read
#   hardware info from the host OS; they do **not** expose HTTP ports anymore.
# ============================================================================
services:
  # ========================================================================
  # PHASE 1: AUTOMATED DEVICE REGISTRATION AND INITIALIZATION
  # ========================================================================

  # ARM64 Init Service for Raspberry Pi devices
  # FULLY AUTOMATED - No user interaction required
  alm_init_arm64:
    image: europe-west1-docker.pkg.dev/effective-pipe-424209-r1/alm-init/alm-init:${ALM_INIT_ARM64_TAG:-latest}
    container_name: alm_init_arm64
    network_mode: host # Use host network to access Host OS local IP
    # No ports exposed - fully automated registration via API
    volumes:
      # Shared configuration volumes (init generates, main app consumes)
      - alm_config:/opt/alm/config # Generated configurations
      - alm_persist:/opt/alm/persist # Persistent device data
      # Host system access for device detection
      - /proc/cpuinfo:/proc/cpuinfo:ro # For serial number detection
      - /etc/hostname:/etc/hostname:ro # For hostname detection
    environment:
      - DEVICE_ARCH=arm64
      - MANAGEMENT_API_URL=https://fapi-staging.strealer.io
      - REGISTRATION_API_URL=http://public-staging.strealer.io/register/alm
      - X_API_KEY=cwSL8sAAiT7QWyvMulL4f6Mtmet7klzV
    restart: "no" # Run once until INIT_DONE=1, then exit
    # No healthcheck - init container should exit cleanly after completing registration
  # AMD64 Init Service for x86_64 servers
  # FULLY AUTOMATED - No user interaction required
  alm_init_amd64:
    image: europe-west1-docker.pkg.dev/effective-pipe-424209-r1/alm-init/alm-init:${ALM_INIT_AMD64_TAG:-latest}
    container_name: alm_init_amd64
    network_mode: host # Use host network to access Host OS local IP
    # No ports exposed - fully automated registration via API
    volumes:
      # Shared configuration volumes
      - alm_config:/opt/alm/config
      - alm_persist:/opt/alm/persist
      # Host system access for device detection
      - /proc/cpuinfo:/proc/cpuinfo:ro
      - /etc/hostname:/etc/hostname:ro
    environment:
      - DEVICE_ARCH=amd64
      - MANAGEMENT_API_URL=https://fapi-staging.strealer.io
      - REGISTRATION_API_URL=http://public-staging.strealer.io/register/alm
      - X_API_KEY=cwSL8sAAiT7QWyvMulL4f6Mtmet7klzV
    restart: "no" # Run once until INIT_DONE=1, then exit
    # No healthcheck - init container should exit cleanly after completing registration
  # Dedicated telemetry worker that keeps cron_5m.sh running every five minutes.
  # Shares the same configuration and persistence volumes so it can reuse device
  # credentials and INIT status generated by the init container.
  alm_telemetry:
    image: europe-west1-docker.pkg.dev/effective-pipe-424209-r1/alm-telemetry/alm-telemetry:${ALM_TELEMETRY_TAG:-latest}
    container_name: alm_telemetry
    network_mode: host
    volumes:
      - alm_config:/opt/alm/config
      - alm_persist:/opt/alm/persist
      - /proc/cpuinfo:/proc/cpuinfo:ro
      - /etc/hostname:/etc/hostname:ro
      - /etc/os-release:/host/etc/os-release:ro
    restart: unless-stopped # Cron runner should always stay online
  # ========================================================================
  # OBSERVABILITY: VECTOR LOG COLLECTOR
  # ========================================================================
  
  # Vector log collector - ships logs to central Loki instance
  # Collects nginx logs, docker container logs, and system logs
  alm_vector:
    image: timberio/vector:0.34.1-alpine
    container_name: alm_vector
    
    # Resource limits for Raspberry Pi 4
    mem_limit: 512m
    mem_reservation: 256m
    cpus: 1.0
    
    volumes:
      # Vector configuration
      # Prod: Config distributed by Puppet to host path
      - /opt/alm/config/vector.yaml:/etc/vector/vector.yaml:ro
      
      # Data directory for disk buffering
      - alm_vector_data:/var/lib/vector:rw
      
      # Log file access - nginx logs from alm_* containers
      - /var/log/nginx:/var/log/nginx:ro
      
      # Docker socket for container logs
      - /var/run/docker.sock:/var/run/docker.sock:ro
      
      # Journald for system logs
      - /var/log/journal:/var/log/journal:ro
      - /run/systemd/journal:/run/systemd/journal:ro
      
    environment:
      # Loki endpoint - set via .env file or override in production
      - LOKI_ENDPOINT=${LOKI_ENDPOINT:-http://104.155.91.159:3100}
      - PROMETHEUS_ENDPOINT=${PROMETHEUS_ENDPOINT:-http://104.155.91.159:9090}
      - VECTOR_LOG=info
      # Reduce worker threads for Raspberry Pi (4 cores = 2 threads recommended for background)
      - VECTOR_THREADS=2
      # In production, if using alm_config volume:
      # - VECTOR_CONFIG=/opt/alm/config/observability/vector.toml
      
    ports:
      - "8686:8686"  # Vector API for health checks
      - "9598:9598"  # Prometheus metrics endpoint
      
    restart: unless-stopped
    
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8686/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
      
    # Vector should start after main app is running
    depends_on:
      - alm_telemetry
      
    # Prevent OOM killer from targeting Vector
    oom_score_adj: -500

  # ========================================================================
  # PHASE 2: MAIN ALM APPLICATION CONTAINERS
  # ========================================================================

  # ARM64 Main Service for Raspberry Pi devices (starts after init completion)
  alm_arm64:
    image: europe-west1-docker.pkg.dev/effective-pipe-424209-r1/alm-app/alm-app:${ALM_APP_ARM64_TAG:-latest}
    container_name: alm_arm64
    ports:
      - "80:80" # Main HTTP traffic for content delivery
    volumes:
      # Configuration files generated by init container
      - alm_config:/opt/alm/config:ro # Read-only access to generated configs
    environment:
      - HOST_IP_FILE=/host_ip
      - INIT_REQUIRED=true # Wait for init completion before starting
    depends_on:
      alm_init_arm64:
        condition: service_completed_successfully # Wait for init to complete
    restart: unless-stopped # Auto-restart main service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
  # AMD64 Main Service for x86_64 servers (starts after init completion)
  alm_amd64:
    image: europe-west1-docker.pkg.dev/effective-pipe-424209-r1/alm-app/alm-app:${ALM_APP_AMD64_TAG:-latest}
    container_name: alm_amd64
    ports:
      - "80:80" # Main HTTP traffic for content delivery
    volumes:
      # Configuration files generated by init container
      - alm_config:/opt/alm/config:ro
    environment:
      - HOST_IP_FILE=/host_ip
      - INIT_REQUIRED=true # Wait for init completion before starting
    depends_on:
      alm_init_amd64:
        condition: service_completed_successfully # Wait for init to complete
    restart: unless-stopped # Auto-restart main service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
# ============================================================================
# SHARED VOLUMES FOR CONFIGURATION MANAGEMENT
# ============================================================================
volumes:
  # Main configuration volume (shared between init and main containers)
  # Docker-managed named volume - no host directories needed!
  alm_config:
  # Persistent data volume for device-specific information
  # Docker-managed named volume - no host directories needed!
  alm_persist:
  # Vector data volume for disk buffering
  alm_vector_data:

# ============================================================================
# DEPLOYMENT NOTES - ZERO HOST SETUP REQUIRED!
# ============================================================================
#
# ZERO-SETUP DEPLOYMENT:
# 1. Copy docker-compose.yml to any directory (e.g., /opt/alm)
# 2. Run: `docker compose up -d alm_init_arm64` (or `_amd64`) so init can
#    populate the shared volumes. After INIT_DONE=1, start `alm_arm64` and
#    `alm_telemetry`.
#
# ARCHITECTURE SELECTION:
# - ARM64 (Raspberry Pi): start `alm_init_arm64` + `alm_arm64`
# - AMD64 (Servers): start `alm_init_amd64` + `alm_amd64`
#
# CONFIGURATION FLOW:
# 1. Init writes configs/keys into `alm_config` + `alm_persist`
# 2. Main copies configs into /etc and runs ALM Java process
# 3. Telemetry container reuses the same volumes for cron-based reporting
#
# NETWORK NOTES:
# - Init containers rely on host network only for device introspection and API
#   calls; no HTTP ports are exposed during registration.
# - Main containers expose port 80 for cached content.
#
# REGISTRY ACCESS:
# - Ensure the Puppet-managed `docker login` has run (or manually source
#   `/opt/alm/config/gcp-registry-token`) before calling `docker compose pull`
#   on production devices so Artifact Registry pulls work.
# ============================================================================
